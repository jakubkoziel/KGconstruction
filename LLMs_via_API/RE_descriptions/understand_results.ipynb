{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'rel_info.json'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_17988\\836722829.py\u001B[0m in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[1;32mwith\u001B[0m \u001B[0mopen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'rel_info.json'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'r'\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mf\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m     \u001B[0mrel_info\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mjson\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mload\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mf\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[1;32mwith\u001B[0m \u001B[0mopen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mos\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mjoin\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'..'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'evaluations'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'NERs_ready_for_eval'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'dev_true_separately.json'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'r'\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mf\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m     \u001B[0mdev_true\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mjson\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mload\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mf\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[1;32mwith\u001B[0m \u001B[0mopen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mos\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mjoin\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'dev_true_separately'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'v6'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'deepseek-reasoner'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'doc_0.json'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'r'\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mf\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'rel_info.json'"
     ]
    }
   ],
   "source": [
    "with open('rel_info.json', 'r') as f:\n",
    "    rel_info = json.load(f)\n",
    "with open(os.path.join('..', 'evaluations', 'NERs_ready_for_eval', 'dev_true_separately.json'), 'r') as f:\n",
    "    dev_true = json.load(f)\n",
    "with open(os.path.join('dev_true_separately', 'v6', 'deepseek-reasoner', 'doc_0.json'), 'r') as f:\n",
    "    pred = json.load(f)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "document = copy.deepcopy(dev_true[0])\n",
    "for i in range(len(document['vertexSet'])):\n",
    "    entity = document['vertexSet'][i][0]\n",
    "    document['sents'][entity['sent_id']][entity['pos'][0]] = '<<' + str(i) + '>>' + \\\n",
    "                                                             document['sents'][entity['sent_id']][entity['pos'][0]]\n",
    "    document['sents'][entity['sent_id']][entity['pos'][1] - 1] = document['sents'][entity['sent_id']][\n",
    "                                                                     entity['pos'][1] - 1] + '<<' + str(i) + '>>'\n",
    "\n",
    "concatenated_sents = []\n",
    "for i in range(len(document['sents'])):\n",
    "    concatenated_sents.append(' '.join(document['sents'][i]))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "updated = []\n",
    "for p in pred:\n",
    "    updated.append({\n",
    "        'h_idx': p['h_idx'],\n",
    "        't_idx': p['t_idx'],\n",
    "        'r': rel_info[p['r']],\n",
    "        'evidence': p['evidence'],\n",
    "    })\n",
    "print(concatenated_sents)\n",
    "updated\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rel_info"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open(os.path.join('..', 'evaluations', 'NERs_ready_for_eval', 'dev_true.json'), 'r') as f:\n",
    "    dev_combined = json.load(f)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "document = copy.deepcopy(dev_combined[0])\n",
    "for i in range(len(document['vertexSet'])):\n",
    "    for j in range(len(document['vertexSet'][i])):\n",
    "\n",
    "        entity = document['vertexSet'][i][j]\n",
    "        document['sents'][entity['sent_id']][entity['pos'][0]] = '<<' + str(i) + '>>' + \\\n",
    "                                                                 document['sents'][entity['sent_id']][entity['pos'][0]]\n",
    "        document['sents'][entity['sent_id']][entity['pos'][1] - 1] = document['sents'][entity['sent_id']][\n",
    "                                                                         entity['pos'][1] - 1] + '<<' + str(i) + '>>'\n",
    "\n",
    "concatenated_sents = []\n",
    "for i in range(len(document['sents'])):\n",
    "    concatenated_sents.append(' '.join(document['sents'][i]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "updated = []\n",
    "for p in dev_combined[0]['labels']:\n",
    "    updated.append({\n",
    "        'h_idx': p['h'],\n",
    "        't_idx': p['t'],\n",
    "        'r': rel_info[p['r']],\n",
    "        'evidence': p['evidence'],\n",
    "    })\n",
    "print(concatenated_sents)\n",
    "updated"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.read_csv('relations_more_info.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df[['property', 'propertyLabel', 'aliases', 'description']]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.property = df.property.apply(lambda x: x.split('/')[-1])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df[['property', 'propertyLabel', 'aliases', 'description']].to_csv('selected_columns_relations.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df[df.property == 'P'+'355']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('selected_columns_relations.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i, row in df2.iterrows():\n",
    "    if row['propertyLabel'] != rel_info[row['property']]:\n",
    "        print(row['property'], row['propertyLabel'])\n",
    "        print(rel_info[row['property']])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# For existing dataframe:\n",
    "property_dict = (\n",
    "    df2.set_index('property')\n",
    "    .rename(columns={'property label': 'propertyLabel'})\n",
    "    .to_dict(orient='index')\n",
    ")\n",
    "\n",
    "# Optional: Convert string aliases to lists\n",
    "if True:\n",
    "    for prop in property_dict:\n",
    "        if isinstance(property_dict[prop]['aliases'], str):\n",
    "            property_dict[prop]['aliases'] = [a.strip() for a in property_dict[prop]['aliases'].split(',')]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "property_dict"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open('property_dict.json', 'w') as f:\n",
    "    json.dump(property_dict, f)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
